{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Basics of machine learning and feedforward neural networks\n",
    "\n",
    "### Name: [INPUT-YOUR NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This assignment includes:\n",
    "\n",
    "## 1. Mathematical questions (20 points)\n",
    "\n",
    "## 2. Coding in Python (pytorch): train softmax classifiers on MNIST (80 points)\n",
    "\n",
    "2.0 Install and configure: python ([Anaconda platform](https://docs.anaconda.com/anaconda/install/) recommended), [Jupyter Notebook](https://jupyter.org/install) and [pytorch](https://pytorch.org/get-started/) \n",
    "\n",
    "2.1 Read provided code (with pytorch) \n",
    "\n",
    "2.2 Complete the code of mini-batch SGD for linear softmax classifier\n",
    "\n",
    "2.3 Record and plot results to show the loss and accuracy convergence (against #epoch)\n",
    "\n",
    "2.4 Complete the code of multilayer feedforward network and train the nonlinear models\n",
    "\n",
    "## Submission:\n",
    "\n",
    "* Convert the ipynb file to html file (**save the execution outputs**)\n",
    "    \n",
    "* Upload both your ipynb and html files to blackboard.\n",
    "\n",
    "* Deadline: Feb 28, 11:59:59 PM, Pacific time.\n",
    "\n",
    "## Hints for the coding part:\n",
    "\n",
    "1. If you are more comfortable to use other libraries such as Keras and TensorFlow, you can change the code accordingly.\n",
    "\n",
    "2. Implement your code using the computation of vectors and matrics, rather than the for-loop to compute each element in vectors and matrics.\n",
    "\n",
    "3. Plots should be clear and easy to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Mathematical questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Equivalence between: MLE using Bernoulli distribution and logistic regression\n",
    "\n",
    "Read Section 5.5, 6.2.2.2, 6.2.2.3 in [Deep Learning Book](https://www.deeplearningbook.org/). Explain why logistic regression is equivalent to Maximum likelihood estimation.\n",
    "\n",
    "Optional reading material that may help: [this lecture notes](https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch12.pdf), Section 12.2.1 and 12.2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Determine the convexity of a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.1. Suppose we have a functioin $f({\\bf x}) = \\log( \\sum_{i=1}^n \\exp(x_i) )$, where ${\\bf x} \\in \\mathbb R^d$ and $x_i$ is the $i$-th element of ${\\bf x}$ (so {\\bf x} is a vector and $x_i$ is a scalar). \n",
    "\n",
    "Question: is $f({\\bf x})$ a convex function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.2. We introduced logistic regression for binary classification. Its objective function is \n",
    "\\begin{align*}\n",
    "f({\\bf w}) = \\frac{1}{n} \\sum_{i=1}^n \\log( 1 + \\exp( - y_i {\\bf w}^\\top {\\bf x}_i ) ) + \\frac{\\lambda}{2} \\| {\\bf w} \\|^2  ,\n",
    "\\end{align*}\n",
    "where ${\\bf x}_i \\in \\mathbb R^d, y_i \\in \\{ -1, +1 \\}$. \n",
    "\n",
    "Question: is the above objective function convex or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "We can use the second order derivatives $\\nabla^2 f$ to see whether a function $f$ is convex: if the second order derivatives are positive definite (when $f$ has vector inputs), or positive number (when $f$ has scalar inputs). Suppose $f({\\bf x}) = 1/2 * {\\bf x}^\\top {\\bf x}$. Then we compute its first order and second order derivative:\n",
    "\\begin{align*}\n",
    "&\n",
    "\\nabla f({\\bf x}) = {\\bf x} \\\\\n",
    "&\n",
    "\\nabla^2 f({\\bf x}) = {\\bf 1} ,\n",
    "\\end{align*}\n",
    "where ${\\bf 1}$ is positive definite ([why?](https://math.stackexchange.com/questions/263957/why-is-the-identity-the-only-symmetric-0-1-matrix-with-all-eigenvalues-posit#:~:text=It%20does%20not%20give%20much,simultaneously%20has%20all%20three%20properties.&text=Symmetric%20and%20all%20eigenvalues%20positive,1's%20on%20its%20diagonal.)).\n",
    "\n",
    "Hint: you can find how to compute derivatives of vectors/matrics in Section 2 in [The Matrix Cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. (Read and run) Load MNIST dataset using pytorch and scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (60000, 784)\n",
      "Shape of x_test: (10000, 784)\n",
      "Shape of y_train: (60000,)\n",
      "Shape of y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_set = datasets.MNIST('./data', train=True, download=True)\n",
    "test_set = datasets.MNIST('./data', train=False, download=True)\n",
    "\n",
    "x_train = train_set.data.numpy()\n",
    "x_train = x_train.reshape(len(x_train),-1)\n",
    "x_test = test_set.data.numpy()\n",
    "x_test = x_test.reshape(len(x_test),-1)\n",
    "\n",
    "y_train = train_set.targets.numpy()\n",
    "y_test = test_set.targets.numpy()\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "\n",
    "print('Shape of y_train: ' + str(y_train.shape))\n",
    "print('Shape of y_test: ' + str(y_test.shape))\n",
    "\n",
    "# calculate mu and sig using the training set\n",
    "d = x_train.shape[1]\n",
    "mu = numpy.mean(x_train, axis=0).reshape(1, d)\n",
    "sig = numpy.std(x_train, axis=0).reshape(1, d)\n",
    "\n",
    "# transform the training features\n",
    "x_train = (x_train - mu) / (sig + 1E-6)\n",
    "\n",
    "# transform the test features\n",
    "x_test = (x_test - mu) / (sig + 1E-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. (Read and run) Visualize a random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its label is\n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = x_train.shape[0]\n",
    "random_index = numpy.random.randint(d, size=1)[0]\n",
    "plt.imshow(x_train[random_index].reshape(28,28))\n",
    "print('Its label is')\n",
    "print(y_train[random_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. (Read and run) Define softmax function and cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\"implement the softmax functions\n",
    "    input: numpy ndarray\n",
    "    output: numpy ndarray\n",
    "    \"\"\"\n",
    "    exp_list = numpy.exp(z)\n",
    "    result = 1/sum(exp_list) * exp_list\n",
    "    result = result.reshape((len(z),1))\n",
    "    assert (result.shape == (len(z),1))\n",
    "    return result\n",
    "\n",
    "def neg_log_loss(pred, label):\n",
    "    \"\"\"implement the negative log loss\"\"\"\n",
    "    loss = -numpy.log(pred[int(label)])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 (Read and run) Functions for implementing linear softmax classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "root = os.path.abspath('.')\n",
    "root += '/configs/'\n",
    "\n",
    "def loadConfig(name):\n",
    "    \"\"\" Read a configuration file as a dictionary\"\"\"\n",
    "    full_path = root + name\n",
    "    json_file = open(full_path, 'r')\n",
    "    cfg = json.load(json_file)\n",
    "    json_file.close()\n",
    "    return cfg  \n",
    "\n",
    "def initialize(num_inputs,num_classes):\n",
    "    \"\"\"initialize the parameters\"\"\"\n",
    "    # num_inputs = 28*28 = 784\n",
    "    # num_classes = 10\n",
    "    w = numpy.zeros((num_classes, num_inputs)) # (10*784)\n",
    "    b = numpy.zeros((num_classes, 1)) # (10*1) \n",
    "    \n",
    "    param = {\n",
    "        'w' : w, # (10*784)\n",
    "        'b' : b  # (10*1)\n",
    "    }\n",
    "    return param\n",
    "\n",
    "def eval(param, hyp, x_data, y_data):\n",
    "    \"\"\" implement the evaluation function\n",
    "    input: param -- parameters dictionary (w, b)\n",
    "           hyp -- hyper-parameter: we use hyp['lambda'] to compute regularization\n",
    "           x_data -- x_train or x_test (size, 784)\n",
    "           y_data -- y_train or y_test (size,)\n",
    "    output: loss and accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    reg_lambda = hyp['lambda']\n",
    "    \n",
    "    # w: (10*784), x: (10000*784), y:(10000,)\n",
    "    loss_list = []\n",
    "    w = param['w'].transpose()\n",
    "    dist = numpy.array([numpy.squeeze(softmax(numpy.matmul(x_data[i], w))) for i in range(len(y_data))])\n",
    "\n",
    "    result = numpy.argmax(dist,axis=1)\n",
    "    accuracy = sum(result == y_data)/float(len(y_data))\n",
    "\n",
    "    loss_list = [neg_log_loss(dist[i],y_data[i]) for i in range(len(y_data))]\n",
    "    loss = sum(loss_list) / len(loss_list) + reg_lambda/2 * numpy.sum(w * w) + reg_lambda/2 * numpy.sum(b * b)\n",
    "    return loss, accuracy\n",
    "\n",
    "def train(param, hyp, x_train, y_train, x_test, y_test,cfg_idx):\n",
    "    \"\"\" implement the train function\n",
    "    input: param -- parameters dictionary (w, b)\n",
    "           hyp -- hyperparameters dictionary\n",
    "           x_train -- (60000, 784)\n",
    "           y_train -- (60000,)\n",
    "           x_test -- x_test (10000, 784)\n",
    "           y_test -- y_test (10000,)\n",
    "    output: train_loss_list, train_acc_list, test_loss_list, test_acc_list\n",
    "           Four lists contain the epoch-wise loss function on training data, accuracy on training data, loss function on testing data, accuracy on testing data, respectively\n",
    "    \"\"\"\n",
    "    num_epoches = hyp['num_epoches']\n",
    "    batch_size = hyp['batch_size']\n",
    "    learning_rate = hyp['learning_rate']\n",
    "    mu = hyp['mu']\n",
    "    reg_lambda = hyp['lambda']\n",
    "    train_loss_list, train_acc_list, test_loss_list, test_acc_list = [],[],[],[]\n",
    "    if bool(hyp['momentum']) == True:\n",
    "        w_velocity = numpy.zeros(param['w'].shape)\n",
    "        b_velocity = numpy.zeros(param['b'].shape) \n",
    "\n",
    "    for epoch in range(num_epoches):\n",
    "        \n",
    "        # select the random sequence of training set\n",
    "        rand_indices = numpy.random.choice(x_train.shape[0],x_train.shape[0],replace=False)\n",
    "        num_batch = int(x_train.shape[0]/batch_size)\n",
    "        \n",
    "        if bool(hyp['learning_decay']) == True:\n",
    "            try:\n",
    "                if test_acc_list[-1] - test_acc_list[-2] < 0.001:\n",
    "                    learning_rate *= hyp['decay_factor']\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            message = 'learning rate: %.8f' % learning_rate\n",
    "            print(message)\n",
    "            logging.info(message)\n",
    "\n",
    "        # for each batch of train data\n",
    "        for batch in range(num_batch):\n",
    "            index = rand_indices[batch_size*batch:batch_size*(batch+1)]\n",
    "            x_batch = x_train[index]\n",
    "            y_batch = y_train[index]\n",
    "\n",
    "            # calculate the stochastic gradient w.r.t w and b\n",
    "            dw, db, batch_loss = mini_batch_gradient(param, x_batch, y_batch, reg_lambda)\n",
    "\n",
    "            param['w'] -= learning_rate * dw\n",
    "            param['b'] -= learning_rate * db\n",
    "            \n",
    "            if (batch+1) % 100 == 0:\n",
    "                message = 'Epoch [%d/%d], Batch [%d/%d], Loss %.4f' % (epoch+1, num_epoches, batch+1, num_batch, batch_loss)\n",
    "                print(message)\n",
    "\n",
    "        train_loss, train_acc = eval(param,hyp,x_train,y_train)\n",
    "        test_loss, test_acc = eval(param,hyp,x_test,y_test)\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_loss_list.append(test_loss)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "        message = 'Epoch %d/%d, Train Loss %.4f, Train Acc %.4f, Test Loss %.4f, Test Acc %.4f' % (epoch+1, num_epoches, train_loss, train_acc, test_loss, test_acc)\n",
    "        print(message)\n",
    "        logging.info(message)\n",
    "    return train_loss_list, train_acc_list, test_loss_list, test_acc_list\n",
    "\n",
    "\n",
    "def plot(train_loss_list, train_acc_list, test_loss_list, test_acc_list, cfg_idx):\n",
    "    \"\"\"store the plots\"\"\"\n",
    "    # epoch_list = list(range(len(loss_list)))\n",
    "    plt.plot(train_loss_list, '-b', label='train loss')\n",
    "    plt.plot(test_loss_list, '-r', label='test loss')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Loss Function')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.title('Loss Function ~ Epoch')\n",
    "    plt.savefig('assets/loss_{}.png'.format(cfg_idx))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(train_acc_list, '-b', label='train acc')\n",
    "    plt.plot(test_acc_list, '-r', label='test acc')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.title('Accuracy ~ Epoch')\n",
    "    plt.savefig('assets/accr_{}.png'.format(cfg_idx))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def main(cfg_idx): \n",
    "#     cfg_idx = args.config\n",
    "    cfg_name = 'config_{}.json'.format(cfg_idx)\n",
    "    hyperpara = loadConfig(cfg_name)\n",
    "\n",
    "    # setting the random seed\n",
    "    numpy.random.seed(1024)\n",
    "\n",
    "    # initialize the parameters\n",
    "    num_inputs = x_train.shape[1]\n",
    "    num_classes = len(set(y_train))\n",
    "    param = initialize(num_inputs,num_classes)\n",
    "\n",
    "    # train the model\n",
    "    train_loss_list, train_acc_list, test_loss_list, test_acc_list = train(param,hyperpara,x_train,y_train,x_test,y_test, cfg_idx)\n",
    "\n",
    "    # plot the loss and accuracy\n",
    "    plot(train_loss_list, train_acc_list, test_loss_list, test_acc_list, cfg_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. (To finish) Implementation of mini-batch SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_gradient(param, x_batch, y_batch, reg_lambda):\n",
    "    \"\"\"implement the function to compute the mini batch gradient\n",
    "    input: param -- parameters dictionary (w, b)\n",
    "           x_batch -- a batch of x (size, 784)\n",
    "           y_batch -- a batch of y (size,)\n",
    "    output: \n",
    "           dw -- derivative for weight w\n",
    "           db -- derivative for bias b\n",
    "           batch_loss -- average loss on the mini-batch samples\n",
    "    \"\"\"\n",
    "    batch_size = x_batch.shape[0]\n",
    "    w_grad_list = []\n",
    "    b_grad_list = []\n",
    "    batch_loss = 0\n",
    "    for i in range(batch_size):\n",
    "        x,y = x_batch[i],y_batch[i]\n",
    "        x = x.reshape((784,1)) # x: (784,1)\n",
    "        E = numpy.zeros((10,1)) #(10*1)\n",
    "        E[y][0] = 1 \n",
    "        \n",
    "        pred = softmax(numpy.matmul(param['w'], x)+param['b']) #(10*1)\n",
    "#         print(pred)\n",
    "\n",
    "        loss = neg_log_loss(pred, y)\n",
    "        batch_loss += loss\n",
    "\n",
    "        w_grad = E - pred\n",
    "        w_grad = - numpy.matmul(w_grad, x.reshape((1,784))) + reg_lambda * param['w'];\n",
    "        w_grad_list.append(w_grad)\n",
    "\n",
    "        b_grad = -(E - pred) + reg_lambda * param['b']\n",
    "        b_grad_list.append(b_grad)\n",
    "\n",
    "    dw = sum(w_grad_list)/batch_size\n",
    "    db = sum(b_grad_list)/batch_size\n",
    "    batch_loss = loss \n",
    "    return dw, db, batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. (Read and run) Train your model using the provided configuration (in *configs/config_sample.json*) untill convergence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [100/600], Loss 0.1584\n",
      "Epoch [1/3], Batch [200/600], Loss 0.0278\n",
      "Epoch [1/3], Batch [300/600], Loss 0.2391\n",
      "Epoch [1/3], Batch [400/600], Loss 0.5268\n",
      "Epoch [1/3], Batch [500/600], Loss 0.1815\n",
      "Epoch [1/3], Batch [600/600], Loss 0.2594\n",
      "Epoch 1/3, Train Loss 0.3052, Train Acc 0.9170, Test Loss 0.3130, Test Acc 0.9155\n",
      "Epoch [2/3], Batch [100/600], Loss 0.0078\n",
      "Epoch [2/3], Batch [200/600], Loss 0.0510\n",
      "Epoch [2/3], Batch [300/600], Loss 0.0566\n",
      "Epoch [2/3], Batch [400/600], Loss 0.4083\n",
      "Epoch [2/3], Batch [500/600], Loss 0.0019\n",
      "Epoch [2/3], Batch [600/600], Loss 0.0013\n",
      "Epoch 2/3, Train Loss 0.2902, Train Acc 0.9197, Test Loss 0.3323, Test Acc 0.9167\n",
      "Epoch [3/3], Batch [100/600], Loss 0.0846\n",
      "Epoch [3/3], Batch [200/600], Loss 0.0063\n",
      "Epoch [3/3], Batch [300/600], Loss 1.2555\n",
      "Epoch [3/3], Batch [400/600], Loss 0.2237\n",
      "Epoch [3/3], Batch [500/600], Loss 0.0076\n",
      "Epoch [3/3], Batch [600/600], Loss 0.2060\n",
      "Epoch 3/3, Train Loss 0.2914, Train Acc 0.9201, Test Loss 0.3375, Test Acc 0.9180\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAElCAYAAAD+wXUWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA06UlEQVR4nO3dd5xU1fnH8c/DSlMQaTH0bkFFVERUDKhRKSoosWKJDUs0GDsqRiyxoAY7lmBLRFF/doyKgpiIChhQsVFEWLAAioACwvL8/jh3ZHaZXWZhZ+7szvf9es2LmblTnr3L3ueec55zrrk7IiIiJVWLOwAREclNShAiIpKSEoSIiKSkBCEiIikpQYiISEpKECIikpIShEgGmNkKM2sbdxxxMbPWZuZmtkXcscimU4KQjDGzuWb2+xi+92Ez+yU6SCdux2Tw+yaY2enJz7l7HXefk6nvLK/oYP1TiX1ySdxxSW5Tdpeq6mZ3vzLuIHLMru4+K+4gpPJQC0KyzsxqmtkIM1sY3UaYWc1oWyMze8nMlprZ92b2tplVi7ZdamYLzGy5mX1uZgeW83sfNrPrkh73NLPCpMdzzewiM/vQzH40syfNrFbS9n5mNs3MlpnZbDPrZWbXA/sBd0Vn5XdFr3Uzax/dr2dmj5rZIjP7ysyuTPqZ/mhm/zGzW8zsBzP70sx6b/reLT8zu9rMno5+3uVm9oGZ7Zq0fceolbTUzGaY2eFJ22qb2a3Rz/Vj9LPUTvr4gWY2z8wWm9kV2fy5ZPMpQUgcrgC6AZ2BXYGuQOJs/0KgEGgMbAtcDriZbQ+cC+zp7nWBQ4C5GYjtaKAX0AboBPwRwMy6Ao8CFwPbAL8D5rr7FcDbwLlRt9K5KT7zTqAe0BboAZwEnJK0fS/gc6ARcDPwDzOz8ga+Ke9J0g94CmgAPA48Z2bVzaw68CLwGvAb4DzgX9HvA+AWYA9gn+i9lwDrkj63O7A9cCBwlZntuBkxSpYpQUgcBgLXuPt37r4IGAacGG1bAzQBWrn7Gnd/28OCYUVATaCjmVV397nuPruM77goOuNdamaLyxHbHe6+0N2/JxwYO0fPnwaMcvfX3X2duy9w98829mFmVgAcAwxx9+XuPhe4NennBfjK3R9w9yLgkejn37aUz9vHzMab2Xdm9rqZHR21un4P3L2RcD5I2idLzeyQpG1T3f1pd18D3AbUIiTxbkAd4EZ3/8Xd3wReAo6LWkGnAoOj/VHk7u+4++qkzx3m7ivdfTownXBCIJWEEoTEoSnwVdLjr6LnAIYDs4DXzGyOmV0GEPWdnw9cDXxnZk+YWVNKd4u7bxPdGpUjtm+S7v9MODgCtADKSkilaQTUYMOft1mq73T3n6O7dUjtOEIrqxlwO+EA/RlwKfDARmLZPWmfbOPuryZtm58UwzpCK65pdJsfPVcy/kaERFLWfiltf0oloAQhcVgItEp63DJ6jugs+0J3bwscBlyQGGtw98fdvXv0XgduKuf3/gRsmfT4t+V473ygXSnbyloSeTGhVVTy511Qju9ONtjdP4haVy+5ey93b+TuB7n7/zbxMyEkQACilkFzwu9kIdAiMWYSScS/GFhF6ftFKjklCMm06mZWK+m2BTAauNLMGptZI+Aq4J8AZnaombWP+tOXEbqWisxsezM7IBrMXgWsjLaVxzSgj5k1MLPfElok6foHcIqZHWhm1cysmZntEG37ljC+sIGo22gMcL2Z1TWzVsAFiZ+3vEqcyVekPczsyOj3cz6wGngXeI+QWC+JxiR6EhL3E1Eso4DbzKypmRWY2d7R70iqACUIybSxhIN54nY1cB0wBfgQ+Aj4IHoOoAMwDlgBTALucfcJhPGHGwlnrd8QBkwvL2csjxH6wecSBl2fTPeN7v4+YWD578CPwFusbxXcDvwhqkK6I8XbzyMcZOcA/yEMAo8qZ+wVYboVnwcxImnb84Sxkh8I4yNHRq2UX4DDgd6EfX8PcFLS+MtFhN/hZOB7QqtOx5UqwnTBIJH8ZmZXA+3d/YS4Y5HcokwvIiIpKUGIiEhK6mISEZGU1IIQEZGUlCBERCSlKrWaa6NGjbx169ZxhyEiUmlMnTp1sbs3TrWtSiWI1q1bM2XKlLjDEBGpNMzsq9K2qYtJRERSUoIQEZGUlCBERCSlKjUGkcqaNWsoLCxk1apVcYdSKdWqVYvmzZtTvXr1uEMRkSyr8gmisLCQunXr0rp1azbvglv5x91ZsmQJhYWFtGnTJu5wRCTLqnwX06pVq2jYsKGSwyYwMxo2bKjWl0ieqvIJAlBy2AzadyL5Ky8SRJyWLl3KPffcs0nv7dOnD0uXLk379VdffTW33HLLJn2XiOQ4d/jmG/jPf+Dhh+HKK+GYY2CPPWD33TPylVV+DCJuiQRxzjnnbLCtqKiIgoKCUt87duzYTIYmIrnGHb7+GmbOhFmz1t8Sj3/6af1rCwqgTRto3x522CG8t4Jb/EoQGXbZZZcxe/ZsOnfuzEEHHUTfvn0ZNmwYTZo0Ydq0aXzyySf079+f+fPns2rVKgYPHsygQYOA9TPDV6xYQe/evenevTvvvPMOzZo14/nnn6d27dqlfu+0adM466yz+Pnnn2nXrh2jRo2ifv363HHHHYwcOZItttiCjh078sQTT/DWW28xePBgIHQpTZw4kbp162Zl/4jknXXrYMGC4gf+5NvKletfW716SAIdOkDPniEZJG6tWoXtGZRXCeL882HatIr9zM6dYcSI0rffeOONfPzxx0yLvnjChAm8//77fPzxx79WBo0aNYoGDRqwcuVK9txzTwYMGEDDhg2Lfc7MmTMZPXo0DzzwAEcffTTPPPMMJ5xQ+gXATjrpJO6880569OjBVVddxbBhwxgxYgQ33ngjX375JTVr1vy1++qWW27h7rvvZt9992XFihXUqlVrM/aIiFBUBPPnp24FzJ4Nq1evf22NGtCuXTjo//73IRkkkkCLFrBFfIfpvEoQuaJr167FykbvuOMOnn32WQDmz5/PzJkzN0gQbdq0oXPnzgDssccezJ07t9TP//HHH1m6dCk9evQA4OSTT+aoo44CoFOnTgwcOJD+/fvTv39/APbdd18uuOACBg4cyJFHHknz5s0r6CcVqcLWroV581K3AubMgV9+Wf/aWrXCAX+77aBPn/UJoEMHaNYsdBfloLxKEGWd6WfTVltt9ev9CRMmMG7cOCZNmsSWW25Jz549U5aV1qxZ89f7BQUFrExuhpbDyy+/zMSJE3nhhRe49tprmTFjBpdddhl9+/Zl7NixdOvWjXHjxrHDDjts0ueLVClr1sDcuRu2AmbNgi+/DEkiYcstw0G/Y0fo1694d1DTplCt8tUE5VWCiEPdunVZvnx5qdt//PFH6tevz5Zbbslnn33Gu+++u9nfWa9ePerXr8/bb7/Nfvvtx2OPPUaPHj1Yt24d8+fPZ//996d79+48/vjjrFixgiVLlrDLLruwyy67MGnSJD777DMlCMkfq1eHg32q7qCvvgrdRQl16oSz/s6d4Q9/WN8KaN8efvvbCh8kjpsSRIY1bNiQfffdl5133pnevXvTt2/fYtt79erFyJEj6dSpE9tvvz3dunWrkO995JFHfh2kbtu2LQ899BBFRUWccMIJ/Pjjj7g7f/nLX9hmm20YOnQo48ePp6CggI4dO9K7d+8KiUEkZ6xaFbp9UnUHzZsXBo4Ttt46HPS7doXjjy/eEvjNb6pcEihLlbomdZcuXbzk9SA+/fRTdtxxx5giqhq0D6VS+PnnMACcqjuosDCUgSY0aFD8wJ88MNywYX4lAbOp7t4l1Ta1IESk8lixYsMWQCIZLFxY/LWNGm1YHtqhQ6gYatAglvArGyUIEckty5albgXMmhVmEifbdttw4D/ooOKtgHbtYJttYgm/KlGCEJHs++GH1K2AWbNg0aLir23aNBz0S5aHtmsHmtCZUUoQIlLx3OH771O3AmbODNuSNW8eDvz9+xcfG2jXDpLKwiW7lCBEZNO4h7P90rqDkheaNIOWLcNB/6ijig8Mt20LZSwbI/FRghCR0iVWEC2tOyh5jk+1amF9oA4dipeHdugQ1hNKmuwplYMSRIYtXbqUxx9/POVqrukYMWIEgwYNYsstt9xgW8+ePbnlllvo0iVlhZpIetatCyuIlrZ4XGkriHbvXrw7qHXrsK6QVBlKEBlW1nLf6RgxYgQnnHBCygQhkrZ168JcgNIWjyu5gmjbtuGgnygRTXQHtWyZ8RVEJXcoQWRYyeW+hw8fzvDhwxkzZgyrV6/miCOOYNiwYfz0008cffTRFBYWUlRUxNChQ/n2229ZuHAh+++/P40aNWL8+PGlfs/o0aP529/+hrvTt29fbrrpJoqKijjttNOYMmUKZsapp57KX/7yl5RLfksVUFQUZgWnmidQ1gqiBx9cvCXQsmXOLh4n2ZVfCSKG9b5LLvf92muvMXPmTN5//33cncMPP5yJEyeyaNEimjZtyssvvwyENZrq1avHbbfdxvjx42nUqFGp37Fw4UIuvfRSpk6dSv369Tn44IN57rnnaNGiBQsWLODjjz8G+HV571RLfkslsXZtWB8oVXfQnDlhcbmEVCuIJloCObyCqOSO/EoQOeC1117jtddeY7fddgNgxYoVzJw5k/3224+LLrqISy+9lEMPPZT99tsv7c+cPHkyPXv2pHHjxgAMHDiQiRMnMnToUObMmcN5551H3759Ofjgg4HUS35LDvnll+IriCYng7lzU68guvPOxUtEO3SAJk0q5QqikjvyK0HkwHrf7s6QIUM488wzN9g2depUxo4dy5AhQzj44IO56qqr0v7MVOrXr8/06dN59dVXufvuuxkzZgyjRo1KueT3FjFelCQvJVYQTTUoXHIF0bp1w0F/t93g6KOLdwdVwRVEJXfoqJBhJZf7PuSQQxg6dCgDBw6kTp06LFiwgOrVq7N27VoaNGjACSecQJ06dXj44YeLvb+sLqa99tqLwYMHs3jxYurXr8/o0aM577zzWLx4MTVq1GDAgAG0a9eOP/7xj6Uu+b2NliXInKlTYcKE4slg3rzii8fVq7fhCqKJ7qDGjZUEJBZKEBlWcrnv4cOH8+mnn7L33nsDUKdOHf75z38ya9YsLr74YqpVq0b16tW59957ARg0aBC9e/emSZMmpQ5SN2nShBtuuIH9998fd6dPnz7069eP6dOnc8opp7AuWsr4hhtuKHXJb8mAGTPgyivhuefC48QKovvuC3/8Y/GWQJ6tICqVg5b7lo3SPiynuXPh6qvh0UdD99DFF8NZZ4XVRUVyjJb7FsmG776D66+He+8Ng8MXXgiXXRZaByKVkBKEyOZatgxuvTXcVq2CU0+Fq64KC9CJVGJKECKbatUquOce+NvfYMmSsAjdtdfC9tvHHZlIhciLIumqNM6Sbdp3KaxdC//4R6gyuvBC2GMPmDIFxoxRcpAqJaMJwsx6mdnnZjbLzC5Lsb2fmX1oZtPMbIqZdY+er2Vm75vZdDObYWbDNjWGWrVqsWTJEh3oNoG7s2TJEmrVqhV3KLnBHZ55JkxKO/30cCGbN96AV18NSUKkislYF5OZFQB3AwcBhcBkM3vB3T9JetkbwAvu7mbWCRgD7ACsBg5w9xVmVh34j5m94u7vljeO5s2bU1hYyKKSV6mStNSqVYvm6kuHceNgyJDQUthxR3j2WejXT6WpUqVlcgyiKzDL3ecAmNkTQD/g1wTh7iuSXr8V4NHzDiS2VY9um9QEqF69Om3atNmUt4rA5MkhMbzxRljE7qGH4MQTtY6R5IVMdjE1A+YnPS6MnivGzI4ws8+Al4FTk54vMLNpwHfA6+7+XgZjFSnu009hwIAws3n69LBMyxdfhAluSg6SJzKZIFK1vTdoBbj7s+6+A9AfuDbp+SJ37ww0B7qa2c4pv8RsUDR+MUXdSLLZ5s0LZao77wyvvw7DhoVVUgcP1hXRJO9kMkEUAi2SHjcHFpb2YnefCLQzs0Ylnl8KTAB6lfK++929i7t3SaxmKlJuixbBBReEyqR//SskhNmzw3yGunXjjk4kFplMEJOBDmbWxsxqAMcCLyS/wMzam4VRPjPbHagBLDGzxma2TfR8beD3wGcZjFXy1fLloZXQrh3cfjuccEJYVO+228IieSJ5LGOD1O6+1szOBV4FCoBR7j7DzM6Kto8EBgAnmdkaYCVwTFTR1AR4JKqEqgaMcfeXMhWr5KHVq2HkSLjuOli8OIw3XHttqFASESAPFusTKaaoCB57DP761zDecOCBYSZ0165xRyYSi7IW68uLmdQiuIe5C506wSmnwG9+Ewahx41TchAphRKEVH3jx0O3bnDkkbBuHTz9NLz/Pvz+93FHJpLTlCCk6po6FQ4+GA44AL7+Oqyf9NFHYbxBM6BFNkoJQqqezz8P127u0gU++CBUJH3xRZjfoGtvi6RNfy1SdRQWhpLVhx6C2rXDQPQFF8DWW8cdmUilpAQhld+SJXDDDXDXXWEw+txz4fLLw0C0iGwyJQipvFasgL//HW65Jdw/6aRwLehWreKOTKRKUIKQymf1arj//jDJ7bvvoH//cH+nneKOTKRKUYKQyqOoKKyTdNVV8NVX0LMnPP98KGEVkQqnKibJfe4hEey6K5x8MjRsGK7i9uabSg4iGaQEIbntrbdgn31CN9KaNeG6z5Mnh/kNmssgklFKEJKbPvgAevUK3Ujz58MDD8CMGXDUUVBN/21FskF/aZJbZs6EY4+FPfYILYXhw8Nzp5+uSW4iWaa/OMkNCxbANdeE5TBq1oQrr4SLLoJ69eKOTCRvKUFIvL7/Hm66Ce64I1QpnXMOXHEFbLtt3JGJ5D0lCInHTz+FK7jdfDMsWxau5DZsGLRpE3dkIhJRgpDs+uWXMOB87bXw7bdw+OFhktsuu8QdmYiUoAQh2bFuHYweDUOHwpdfwu9+B//3f6GEVURykqqYJLPc4aWXoHPn0I1Urx688gpMmKDkIJLjlCAkc95+G/bbDw47DFauDC2IqVPD/AZNchPJeUoQUvGmT4e+fUM30pdfwsiR8MknYX6DJrmJVBr6a5WKM3s2DBwYupMmTQrlqzNnwplnQvXqcUcnIuWkQWrZfF9/HaqSHngAatQIF+u5+GLYZpu4IxORzaAEIZvuhx/CPIbbbw8L6Q0aFGZAN2kSd2QiUgGUIKT8fv45zHy+6Sb48Uc4/vgwya1du7gjE5EKpAQh6VuzBh58MHQnff01HHooXH89dOoUd2QikgFKELJx69bBk0+GSW6zZ0P37uG6DN27xx2ZiGSQqpikdO4wdizsvnvoRtpqK3j5ZZg4UclBJA8oQUhq//0v9OgR5jMsXx6uBf2//0GfPprkJpInlCCkuA8/DDOfu3cPcxjuuQc+/TS0IDTJTSSv6C9egjlz4MQTwyS3t9+Gv/0NZs2Cs88OcxtEJO9sdJDazLYDLgZaJb/e3Q/IYFySLd98E5bbvv9+KCiASy4JtwYN4o5MRGKWThXTU8BI4AGgKLPhSNYsXRqu9zxiBKxeDWecEaqUmjaNOzIRyRHpdDGtdfd73f19d5+auKXz4WbWy8w+N7NZZnZZiu39zOxDM5tmZlPMrHv0fAszG29mn5rZDDMbXM6fS0qzcmVIDG3bhm6kww8PYwz33qvkICLFpJMgXjSzc8ysiZk1SNw29iYzKwDuBnoDHYHjzKxjiZe9Aezq7p2BU4EHo+fXAhe6+45AN+BPKd4r5bFmTehGat8+dCF16wYffBCW4O7QIe7oRCQHpdPFdHL078VJzznQdiPv6wrMcvc5AGb2BNAP+OTXD3FfkfT6raLPxd2/Br6O7i83s0+BZsnvlTStWwdPPRW6j2bODBfpGT06LMUtIlKGjSYId9/Uq8g3A+YnPS4E9ir5IjM7ArgB+A3QN8X21sBuwHubGEd+cofXXoMhQ8L8hZ13hhdeCMtjaB6DiKRho11MZlbdzP5sZk9Ht3PNLJ3F/VMdhXyDJ9yfdfcdgP7AtSW+uw7wDHC+uy8rJb5B0fjFlEWLFqURVh5491044IBw5bYffoDHHoNp08L8BiUHEUlTOmMQ9wJ7APdEtz2i5zamEGiR9Lg5sLC0F7v7RKCdmTWCkJgIyeFf7v5/Zbzvfnfv4u5dGjdunEZYVdiMGdC/P+y9d7iC2513wuefh2tBFxTEHZ2IVDLpjEHs6e67Jj1+08ymp/G+yUAHM2sDLACOBY5PfoGZtQdmu7ub2e5ADWCJmRnwD+BTd78tnR8kr82dC3/9a2gp1K0b5jUMHgx16sQdmYhUYukkiCIza+fuswHMrC1pzIdw97Vmdi7wKlAAjHL3GWZ2VrR9JDAAOMnM1gArgWOiZNEdOBH4yMymRR95ubuPLefPV7V9911Ybvvee0ML4aKL4NJLoWHDuCMTkSrA3DcYFij+ArMDgYeAOYRxhVbAKe4+PvPhlU+XLl18ypQpcYeReT/+CLfeCrfdBqtWwWmnwVVXQbNmcUcmIpWMmU119y6ptqVTxfSGmXUAtickiM/cfXUFxyjpWLUK7r4bbrgBliyBo48OF+/Zbru4IxORKqjUBGFmB7j7m2Z2ZIlN7cyMsgaOpYKtXQuPPAJXXw2FhXDIIWEW9O67xx2ZiFRhZbUgegBvAoel2OaAEkSmucMzz8CVV4ZqpG7dwkB0z55xRyYieaDUBOHuf43uXuPuXyZviyqTJFPcYdy4MMlt6lTo2BGeey6sm6R5DCKSJenMg3gmxXNPV3QgEnn/ffj97+Hgg2HxYnj44XARn379lBxEJKvKGoPYAdgJqFdiHGJroFamA8s7n3wSupKefRYaN4bbb4czz4SaNeOOTETyVFljENsDhwLbUHwcYjlwRgZjyi9ffRUGnx99FLbaCq65Bs4/P0x4ExGJUVljEM8Dz5vZ3u4+KYsx5YdFi0Il0j33hK6j888PYw6NGsUdmYgIkN4YxFlmtk3igZnVN7NRmQupilu2LLQY2raFO+4I14GeOTNMfFNyEJEcks5SG53cfWnigbv/YGa7ZS6kKmrVKhg5MiyNsXgx/OEPYZLbDjvEHZmISErptCCqmVn9xIPoanLpJBaBMMntoYfCbOe//AU6dw6VSk89peQgIjktnQP9rcA7ZpYobT0KuD5zIVUR7qEi6corwzWf99wzJIoDD4w7MhGRtGy0BeHujwJ/AL4FvgOOdPfHMh1Ypfbmm2HW84AB62dDv/eekoOIVCrpdhV9BvyQeL2ZtXT3eRmLqrKaMiVUIo0bBy1awKhRYRB6C/XIiUjls9Ejl5mdB/yV0IIoIqzo6kCnzIZWiXz2GQwdCk8/HSqRbrsNzj4bamk+oYhUXumc2g4Gtnf3JZkOptKZPx+GDQtjC1tuGa7qdsEFsPXWcUcmIrLZ0kkQ84EfMx1IpbJ4cbgmw913hzGGP/8ZLr88LJEhIlJFpJMg5gATzOxl4NcLBeXltaJXrIC//x2GD4effoKTTw6thlat4o5MRKTCpZMg5kW3GtEt/6xeDffdB9ddF5bIOOKIcL9jx7gjExHJmHQuOTosG4HkpKIi+Ne/wvWev/oK9t8/dC3ttVfckYmIZFw6VUzjCVVLxbj7ARmJKBe4wwsvwBVXwIwZsMce8MAD4ToNuiaDiOSJdLqYLkq6XwsYAKzNTDg5YMKEMJfh3XfD8hhPPRUmvCkxiEieSaeLaWqJp/5rZm9lKJ74fPBBqER69VVo3hwefDAMQmuSm4jkqXS6mBokPawG7AH8NmMRZduyZXDGGTBmDDRoALfcAuecA7Vrxx2ZiEis0jk9Tm5BrAW+BE7LTDgxqFMHFi4MM6EvvBDq1Ys7IhGRnFDWNalbuvs8d2+TzYCyrlo1mDhRYwwiIiWUtZrrc4k7ZvZM5kOJkZKDiMgGykoQyUfNtpkOREREcktZCcJLuS8iInmgrEHqXc1sGaElUTu6T/TY3V1LloqIVGGlJgh3L8hmICIikls2eslRERHJT0oQIiKSUkYThJn1MrPPzWyWmV2WYns/M/vQzKaZ2RQz6560bZSZfWdmH2cyRhERSW2jCcLMtjKzatH97czscDOrnsb7CoC7gd5AR+A4Myt5AYU3gF3dvTNwKvBg0raHgV7p/BAiIlLx0mlBTARqmVkzwgH9FMLBe2O6ArPcfY67/wI8AfRLfoG7r3D3RAntViSV07r7ROD7NL5HREQyIJ0EYe7+M3AkcKe7H0FoEWxMM8L1rBMKo+eKf7jZEWb2GfAyoRUhIiI5IK0EYWZ7AwMJB3FIb5G/VOtXpLrw0LPuvgPQH7g2jc8tGdygaPxiyqJFi8r7dhERKUU6CeJ8YAjwrLvPMLO2wPg03lcItEh63BxYWNqLoy6ldmbWKI3PTn7f/e7exd27NG7cuDxvFRGRMqRzwaC3gLcAosHqxe7+5zQ+ezLQwczaAAuAY4Hjk19gZu2B2e7uZrY7UANYUr4fQUREMiGdKqbHzWxrM9sK+AT43Mwu3tj73H0tcC7wKvApMCZqgZxlZmdFLxsAfGxm0wgVT8ckBq3NbDQwCdjezArNrOpcg0JEpBKw9UVEpbzAbJq7dzazgYSryV0KTHX3TtkIsDy6dOniU6ZMiTsMEZFKw8ymunuXVNvSGYOoHs176A887+5r0OquIiJVXjoJ4j5gLmGewkQzawUsK/MdIiJS6aUzSH0HcEfSU1+Z2f6ZC0lERHJBOoPU9czstsRcAzO7ldCaEBGRKiydLqZRwHLg6Oi2DHgok0GJiEj80pkR3c7dByQ9HhaVpYqISBWWTgtiZYlluPcFVmYuJBERyQXptCDOAh41s3rR4x+AkzMXkoiI5IJ0qpimA7ua2dbR42Vmdj7wYYZjExGRGKV9RTl3X+buifkPF2QoHhERyRGbesnRVEt5i4hIFbKpCUJLbYiIVHGljkGY2XJSJwIDamcsIhERyQmlJgh3r5vNQOJUVAQFBXFHISKSWza1i6nKWLcOOneGk06CSZNgI6ufi4jkjbxPED//DD16wHPPwT77wO67w/33w4oVcUcmIhKvvE8QderAXXfBggUwcmRoUZx5JjRrBuedB598EneEIiLxyPsEkVC3bkgM06bBf/8Lhx8eWhI77RRaGE8+Cb/8EneUIiLZowRRglnoanrsMSgshJtugvnz4dhjoWVLuOIKmDcv7ihFRDJPCaIMjRvDJZfArFkwdix07Qo33ABt2oQWxr//HbqkRESqIiWINFSrBr17wwsvwJdfwmWXwXvvhec6dIDhw2Hx4rijFBGpWEoQ5dSqFVx/feh2Gj0amjcPrYzmzeHEE1UqKyJVhxLEJqpRI4xLvPUWfPQRnH46PP98GL/YbTeVyopI5acEUQF23jmUyi5cGEpl3UNFVNOmcO65MGNG3BGKiJSfEkQFqlOneKlsv37wwAMhgfToAU88oVJZEak8lCAyoLRS2eOOgxYtVCorIpWDEkSGlSyV3WsvuPFGlcqKSO5TgsiS5FLZOXM2LJW9+WaVyopIblGCiEFyqewTT4QS2UsvXV8q+847KpUVkfgpQcSoRg045phQKvvxx+tLZffdN5TK3nefSmVFJD5KEDlip52Kl8oCnHWWSmVFJD5KEDkmUSr7v/+FriaVyopIXJQgcpQZ7L132aWyX30Vd5QiUpVlNEGYWS8z+9zMZpnZZSm29zOzD81smplNMbPu6b43nySXyr7yyvpS2bZtQ6nsK6+oVFZEKl7GEoSZFQB3A72BjsBxZtaxxMveAHZ1987AqcCD5Xhv3qlWDXr1Wr+q7JAhoVS2Tx+VyopIxctkC6IrMMvd57j7L8ATQL/kF7j7CvdfCzq3Ajzd9+a7li3huuvWl8q2aBFKZZs1U6msiFSMTCaIZsD8pMeF0XPFmNkRZvYZ8DKhFZH2e2V9qeyECaFUdtCg9aWynTurVFZENl0mE4SleG6Dc1p3f9bddwD6A9eW570AZjYoGr+YsmjRok2NtUrYaSe4885QKnvffWGgW6WyIrKpMpkgCoEWSY+bAwtLe7G7TwTamVmj8rzX3e939y7u3qVx48abH3UVUKdOaEkkSmX791eprIiUXyYTxGSgg5m1MbMawLHAC8kvMLP2ZmbR/d2BGsCSdN4rG5colX30UViwIAxiFxaqVFZE0pOxBOHua4FzgVeBT4Ex7j7DzM4ys7Oilw0APjazaYSqpWM8SPneTMWaDxo1gosvhpkzQ1lst27rS2UPO0ylsiKyIfMqVOrSpUsXnzJlStxhVBrz5oVLoz74IHz7bViC/Mwz4dRTw9wLEan6zGyqu3dJtU0zqfNYolR23rwwLtGyZViGvHlzOOEElcqK5DslCElZKvvCCyqVFcl3ShBSTMlS2WrV1pfK/ulPIYGISH5QgpCUEqWyH3ywvlT2H/+AXXaB3/1OpbIi+UAJQsqUXCpbWBhKZRcsWF8qe/nlKpUVqaqUICRtyaWy//53KJW96aZQ/XTYYTB2LBQVxR2liFQUJQgpt2rV4JBDwppPX34ZWhGTJ0PfvmFV2Ztugjxf9USkSlCCkM2iUlmRqksJQipEqlLZF19cXyo7ciQsXx53lCJSHkoQUuESpbILFoSZ2tWqwdlnh2tVqFRWpPJQgpCMqVMHzjgjlMpOmrRhqezo0bB6ddxRikhplCAk48xCxVOiVHb48NC6OP749aWyc+fGHaWIlKQEIVnVqBFcdNH6Utm99w5VT4lVZVUqK5I7lCAkFmWVyrZvr1JZkVygBCGxSy6VffJJaNWqeKnsf/+rUlmROChBSM6oUQOOPjqUys6YEa5N8eKL0L27SmVF4qAEITmpY0e44w6VyorESQlCclrJUtkjjlhfKrvffiqVFckkJQipFBKlso88EloVw4eHa1YkSmWHDFGprEhFU4KQSqdhw+KlsvvsE5Yhb9sWDj1UpbIiFUUJQiqtRKnsc8+FUtkrroApU1QqK1JRlCCkSmjZEq69dn2pbOvW60tlBw5UqazIplCCkColUSo7fvz6UtmXXgqlsrvuCvfeq1JZkXQpQUiVlSiVXbgwlMpusQWccw40bRr+/eijuCMUyW1KEFLlbbVVKJWdOhXefReOPBJGjYJOnUKp7OOPq1RWJBUlCMkbZrDXXsVLZb/+OoxRqFRWZENKEJKXEqWyX3yRulT25ZdVKiuiBCF5LblUdu7cUCo7dWpIEu3bw403wnffxR2lSDyUIEQiLVqsL5UdMyaUyg4ZEp4fOBD+8x+Vykp+UYIQKaF6dTjqqA1LZffbT6WyEh93WLMm/N/77rtwIvP55zB9Ovzvf5n5TvMqdErUpUsXnzJlStxhSBX0009hYcB77gl/jHXqwIknhhVmd9kl7ugkm9atC1VvK1fCqlXhlrif6efWrUsd029/GwouNoWZTXX3Lim3KUGIpM8d3n8/JIonnwwHiu7dQ6IYMABq1ow7wvyxZk12Dsoln9vckugaNaB2bahVK9wS9zfnua23hgMP3LR4lCBEMmDJEnj44dDlNHs2NG4Mp50WuqRat447uuxw3/Bgmq0D9eZUmZmFg2tFH6g39lytWqEwIpfEliDMrBdwO1AAPOjuN5bYPhC4NHq4Ajjb3adH2wYDZwAGPODuIzb2fUoQEod162DcuNCqePHFcNDs0ye0Knr1goKCzMeQOJuuqANxuu+piLPpTB+UUz1XvXpIEhJTgjCzAuAL4CCgEJgMHOfunyS9Zh/gU3f/wcx6A1e7+15mtjPwBNAV+AX4NyF5zCzrO5UgJG7z58MDD4TbN9+ElsSZZ4ZuqOR+64o+s66Is+lsHqBr1w7dcdlInlK2shLEFhn83q7ALHefEwXxBNAP+DVBuPs7Sa9/F2ge3d8ReNfdf47e+xZwBHBzBuMV2WwtWsA118DQoWFuxb33hlLZdFSvXvaBtWHDzByodTYtpclkgmgGzE96XAjsVcbrTwNeie5/DFxvZg2BlUAfIGXTwMwGAYMAWrZsuZkhi1SMRKnsUUeF2dpz5254gC7ZN62zack1mUwQqc5JUvZnmdn+hATRHcDdPzWzm4DXCWMT04G1qd7r7vcD90PoYtr8sEUq1nbbhZtIZZPJ8fRCoEXS4+bAwpIvMrNOwINAP3dfknje3f/h7ru7+++A74Eyxx9ERKRiZTJBTAY6mFkbM6sBHAu8kPwCM2sJ/B9wort/UWLbb5JecyQwOoOxiohICRnrYnL3tWZ2LvAqocx1lLvPMLOzou0jgauAhsA9FkbJ1iaNpj8TjUGsAf7k7j9kKlYREdmQJsqJiOSxsspcc2xOn4iI5AolCBERSUkJQkREUqpSYxBmtgj4ahPf3ghYXIHhVBTFVT6Kq3wUV/lUxbhauXvjVBuqVILYHGY2pbSBmjgprvJRXOWjuMon3+JSF5OIiKSkBCEiIikpQax3f9wBlEJxlY/iKh/FVT55FZfGIEREJCW1IEREJCUlCBERSUkJIseZ6Vpf5aV9JlIxlCBSyKUDjFeSQSLtM5GqJ+8ThJkVmFk3M9vNzHY3s7qJA0ycBz0zq2VmV0fx5dTvSfts8+VSQq0MtL9Kl+rvsaI+O5OXHK0sbgXaA1sTrnu9hZm96u4vx3wmeg3wG3cvSvxxmFkNd/8lxpgStM/Kwcy6AjsAcwHcfWIutHLM7G/AeHd/Pe5Ykml/lVupf4+b+8F5XeZqZk2Bd929pZnVBHYHdgN2BN529zExxbU98E9g7+jCS6cBPYAlwIfA4+6+OqbYtM/KF9cuUVwfAsuBddG/Y9z9f9mOJymuDoSrOfZw9++j3+UWQK3kS//GEJf2V/niyujfY043w7PgJ+ADM9vT3Ve7+yTgSeC/wJlmtmNMcR1LOCNoYWb7AacDTwBfAEcDO8cUF8DP5OY+Ow7oQO7ts9MJyelE4HrCQWY5MNDMmscUE8DNwN3RwW4f4DbgFeCC6Aw+Ltpf5ZPRY1heJwh3/xEYD9xkZmeZ2VbuvsTdnwDeBQ6NKa5hwFDCf8BXgJvdfay730u41veBccQVxbYUeJ2wz87MoX12NXAlubfP3gW6RuM0C9z9TeApYEvgijjGSszst0AXYJ/o/tWEA8pfCceEM7IdUxLtr3LI+DHM3fP+BhxGOCO4H/gjUINwUDk5hliqJd2vBZwS/ZvoDnwFOCGm/bRLiX12J3BfDuyzC5Pu1wROzqF9VgA8DDwG9C2x7XWgTUxx1QTuAH4EXk963gjXkW8bU1zVgAej/dUnh/ZXLeD2XNtfSXFk5BiWl2MQZnY8sAvQExhJOBtoQOi3OwlYA3zm7udnOa4BQGfgIOBWd3+qxPZzgKPcff9sxpX03c3c/YrocQ2gBfA74ATi22fns/4P42p3/6bE9jj32bbu/q2ZbUPo5todcODfQFPgbHfvFENcTdz96+h+O6COu0+PHh8dxZXV/WVmewIL3X1BdJZ+BOGs/Rdi3F9mNggocvd/RI/bAHXd/cPocVz7KzvHsDizXkyZth6wANgfGACMJZyt9E56TX2is88sx/UR8IfoF/wfYK+k7bUI/eydY9pnk4nO3oAmQC+gYw7ss0lAX+DvwDElttcCjsr2PgO2IbQaxhLOeg8hVOXsDZwX7cu/xRDX1sC9UVwTgO1S7M8vCAP92f49jgeaJz23BeFkKe799S3wKXA8Sa37HNhfWTmGZe2HypVbdDB5scRzJwP/A+4p+Z8gi3H9ndBqSDy+mHBmkGjlFcS4z+4EPozu/wYYB4wmlCE+FldshCb/zdH944FFwF/i+h0mxXVftM9qAOcSzoBHANsnvSaryTT6zrui/+PbAtcBI5O2VSdclewPMf3/ujq6v22USIcATWPeX3dGieng6P97k6RtBUBj4IgY4sraMSwfB6knAD+Y2clmVh/A3R8hDGI2JFTCZFXUXfMZ8GjS06OB1u7uUbN2nJnViiG2aoSEMMXMHgImAs+7+3GEyqCGQMcY4qoDfEcYzMfdHyd0S3QinHnGwsxqA3WAie7+i7vfRWjF/AyMNbOjIPuzvc2sPaE78M/u/i0hWXQ2sx7RS2q4+2J3fzrLcbUBzib8/we4kdBluTfwnpmdArHsrx2BfYEr3P01YAXwmpl1i16yzt0Xufuz2YwrMoEsHcPyKkGYmbn7T8DThGb/sWbW3swauvv3hGZZ1kvWPEzk+heQ6Bc24BugZlQXfgnwpruviiG2dcBLwDDgPWCGu98Z7csVhD7iXWKIawVwi7uvjmaSGvABMA/4V1SKmHXuvpKQ6PuaWWczq+nuy939cuACwjhEHKoDf/cwR6Sah7GaJ4Fdo+2Pm9nJMcS1HDgfONjMJgE7u/uf3P1w4BziS/a/BS5JJCZ3PwN4HDg8ehzL4G22j2F5OUgNYGY9gTOBVcBSQvN6e3fPeoKIfukb/CLM7CTgKuA7d4/lgFcinhpAPXdfFD3uCdzo7t3Kel+GYkm5z6JtQ4Ft3f3cLIeV+P56wKVAc+BZYLq7z4nmZ9zl7ruW+QGZi6tBdBBJPO4JnEYYl7jR3X8XU1y1CPN+jgf+69EMYDM7CLjK3feLI66k+Ao8zM7fkVAM8QOhOuiHmOPqSYaPYXmbIBLMrA9hQKw28JG7fxJzPL8e+KLm43RClcRmT5uvSFFlzm3A2Gx3S6SIpZq7r0v6twWhy2R2zHH9EehPaNW0JvwB3+7uT8YX1XpmtgWhVdgKON3dn4s5ni2BtVGLGjN7Gxjh7s9kOY6yTj6qE8bdbnT3admMqzSZPIblRYIws+0IJZnfEH7mj2MOCSg9rsSBLrp/oLu/kWuxRV06Hdz9i1yKK5uxpIitWKKKntsa2IMw47Wau78bV1ylbLsM2N3dj85yWKXGFSWu3sBh7j4ol+KKuuh2zvYxJBqraUM42fiaMKZV4O5rM/q9VT1BmFkz4BlgGVBIaI7NA55w97nRGUFvwplwRnf2JsS1fzRAllVpxnYg8Fo2D8ppxLUF0Ifs/y6TE0I1Qhe1J7omshVHunGVeE19Qmvr2xyLq2YU1/JciisOZtaEMF60jjBY/nhUlJHYXp1Q2fRSRf+/z4dB6ksIKzAeDNxEKDmsC5xtZo2APYHa2TyglCOuBlmOqTyxbRPDGfvG4upKPL/L283sPjNr7O7rEsmB8AeNmfU2szjGHVLGFbX+El0TjbKZHMoRV5tsJoc04+ptZlmf2AjcAPzb3XsSylj/amFxyoR9CCf7Ff7/Ph8SxGTCxCXc/XN3f4GQjesDg939HcJaL7kYVywro+ZwbDn3u7SwUNsfCDOkx5nZxVF8RdEBpiGhS+yzMj4mzrjm5WBczYEvczCuFsDnWY6rGWGM6LEonrHAa8CR0fbmhAmhL2YkAM/yJI9s3whn4S8TJi91TXp+a8Is15aKq3LElotxEVotl0X3ewDPA+8QTaAC/gR0UlyKazNi25mwHEri8R7Av6L7LxAKDDLy3VV+DAJ+7cM7EdieMMDzJNAWuMndd1BclSe2XIwrMXgZ3a9OKNc8ibB+UA13b6e4FNdmxJVc2VidUK10PzCLcKJ0cMa+Ox8SBICZbUU4S+hJ+MWPJ1yEZJziSi1XY8vVuJJZuOzjQsJCgf+OO54ExVU+ORzXbYQJhge4+4SMfU++JIhkUYVCgbuviTuWZLkaF+RubDkc10BggLsfGXcsyRRX+eRwXDsAJ3q0unLGvicfE4RIpkVVTFu5+7K4Y0mmuMonV+OC7Mz9UYIQEZGU8qHMVURENoEShIiIpKQEISIiKSlBiJSDmRWZ2bSk22UV+NmtzSwnFpIUgbBErIikb6W7d447CJFsUAtCpAKY2Vwzu8nM3o9u7aPnW5nZG2b2YfRvy+j5bc3sWTObHt0SF4QqMLMHzGyGmb1m4RKmIrFQghApn9olupiOSdq2zMPVvO4CRkTP3QU86u6dCJeVvSN6/g7gLQ9Xl9sdmBE93wG42913IlwlbEBGfxqRMmgehEg5mNkKd6+T4vm5hGUP5kTr5Xzj7g3NbDHQxN3XRM9/7e6NzGwR0NzdVyd9RmvgdXfvED2+FKju7tdl4UcT2YBaECIVx0u5X9prUlmddL8IjRNKjJQgRCrOMUn/ToruvwMcG90fCPwnuv8GcDaE5RwsXJpUJKfo7ESkfGqb2bSkx/9290Spa00ze49w4nVc9NyfgVHRBWgWAadEzw8G7jez0wgthbMJy5eL5AyNQYhUgGgMoou7L447FpGKoi4mERFJSS0IERFJSS0IERFJSQlCRERSUoIQEZGUlCBERCQlJQgREUlJCUJERFL6f65nlwntf4zAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    cfg_idx = 'sample'\n",
    "    \n",
    "    import logging\n",
    "    logging.basicConfig(filename=\"./logs/{}.log\".format(cfg_idx), filemode=\"w\", format=\"%(message)s\", level=logging.DEBUG)\n",
    "    \n",
    "    main(cfg_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. (To finish) Does $\\lambda$ impact the accuracy on training and testing data?\n",
    "Please use different values for $\\lambda \\in \\{ 0, 0.0001, 0.001, 0.01, 0.1, 1 \\}$ in the above linear classifier.\n",
    "For the six values of $\\lambda$:\n",
    "\n",
    "(1) Plot loss function values on training and testing data.\n",
    "\n",
    "(2) Plot accuracy on training data and testing data.\n",
    "\n",
    "(3) Use these plots to conclude whether regularization may help generalization performance, and explain why you can draw this conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. (Read and run) Train feedforward networks with one hidden layer (one activation layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.3197\n",
      "Epoch [1/5], Step [200/600], Loss: 0.3180\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1519\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0995\n",
      "Epoch [1/5], Step [500/600], Loss: 0.2435\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1017\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0856\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1734\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0526\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0824\n",
      "Epoch [2/5], Step [500/600], Loss: 0.1192\n",
      "Epoch [2/5], Step [600/600], Loss: 0.1135\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0323\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0999\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0601\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0381\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0471\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0809\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0370\n",
      "Epoch [4/5], Step [200/600], Loss: 0.1144\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0340\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0398\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0253\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0673\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0508\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0401\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0841\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0287\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0660\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0138\n",
      "Accuracy of the network on the 10000 test images: 97.66 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.00001)  \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. (To finish) Implement and train a feedforward network with two hidden layers (two activation layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training: plot training and testing accuracy (against #epoches) and answer the question: is there performance difference between one-layer and two-layer network?\n",
    "\n",
    "Hint: you can start with revising code for NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)  \n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)  \n",
    "        self.fc4 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.0169\n",
      "Epoch [1/5], Step [200/600], Loss: 0.0505\n",
      "Epoch [1/5], Step [300/600], Loss: 0.0108\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0395\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0220\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0376\n",
      "Accuracy of the network on the 10000 test images: 98.04 %\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0087\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0329\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0156\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0070\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0133\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0358\n",
      "Accuracy of the network on the 10000 test images: 98.0 %\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0602\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0101\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0158\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0055\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0690\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0080\n",
      "Accuracy of the network on the 10000 test images: 98.06 %\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0288\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0161\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0247\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0081\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0214\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0193\n",
      "Accuracy of the network on the 10000 test images: 98.21 %\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0099\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0035\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0011\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0256\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0252\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0063\n",
      "Accuracy of the network on the 10000 test images: 97.94 %\n"
     ]
    }
   ],
   "source": [
    "my_model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    # Test the model\n",
    "    # In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "        \n",
    "# Code for plotting results\n",
    "###\n",
    "###     \n",
    "        \n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10. (To finish) Use SGD (instead of Adam) to train your two-hidden-layer network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: read [this document](https://pytorch.org/docs/stable/optim.html) for torch.optim to understand how to change optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.11. (To finish) Use SGD to train your two-hidden-layer network with different learning rate values in the range of $\\{ 0, 0.0001, 0.001, 0.01, 0.1, 1 \\}$, and show which learning rate achieves the best testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.12. (To finish) Use Adam to train your two-hidden-layer network with different learning rate values in the range of $\\{ 0, 0.0001, 0.001, 0.01, 0.1, 1 \\}$, and show which learning rate achieves the best testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.13. (To finish) Is the best learning rate for SGD the same with the best learning rate for Adam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
